{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cahier, vous trouverez le protocole selon lequel les séquences observées dans le jeu de données de test ont été créées. Dans le dossier `training_data/degradataion_data`, vous trouverez les $50$ séquences complètes de fonctionnement jusqu'à la défaillance. Ces séquences sont générées à partir d'un modèle théorique qui contient trois modes de défaillance :\n",
    "\n",
    "- mortalité infantile\n",
    "- défaillance du tableau de contrôle\n",
    "- croissance de fissure\n",
    "\n",
    "Les trois modes de défaillance sont \"compétitifs\", c'est-à-dire que le mode de défaillance qui survient en premier sera celui qui provoque la défaillance. Il s'agit de \"fonctionnement jusqu'à la défaillance\" puisque le processus de croissance de fissure est surveillé jusqu'à ce qu'une défaillance se produise (mais la défaillance peut être due à l'un des trois modes de défaillance).\n",
    "\n",
    "Le jeu de données de test que vous avez dans le dossier `testing_data/group_0` est créé à partir des séquences complètes de fonctionnement jusqu'à la défaillance en les tronquant aléatoirement à un moment donné $t_end$, et vous devez prédire la durée de vie utile restante à partir de ce point $t_end$. La troncature est effectuée de la manière suivante :\n",
    "- Si la séquence de fonctionnement jusqu'à la défaillance est plus courte que $7$, c'est-à-dire si le temps jusqu'à la défaillance est inférieur ou égal à $6$, nous conservons la séquence telle quelle.\n",
    "- Si la séquence de fonctionnement jusqu'à la défaillance est plus longue que $7$, c'est-à-dire si le temps jusqu'à la défaillance est supérieur à $6$, elle est tronquée à un point temporel aléatoire $t_end$, généré à partir d'une distribution uniforme de [1, ttf-1].\n",
    "\n",
    "Le code suivant générera un jeu de données de test \"pseudo\" basé sur le jeu de données d'entraînement, que vous pourrez utiliser pour évaluer la performance du modèle que vous avez développé :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m ttf \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrul (months)\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ttf \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m:\n\u001b[0;32m---> 21\u001b[0m     random_integer \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mttf\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrul (months)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m random_integer]\n\u001b[1;32m     24\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m file_name, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/random.py:336\u001b[0m, in \u001b[0;36mRandom.randint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandint\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, b):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return random integer in range [a, b], including both end points.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/random.py:312\u001b[0m, in \u001b[0;36mRandom.randrange\u001b[0;34m(self, start, stop, step)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty range for randrange()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# Stop argument supplied.\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m istop \u001b[38;5;241m=\u001b[39m \u001b[43m_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m width \u001b[38;5;241m=\u001b[39m istop \u001b[38;5;241m-\u001b[39m istart\n\u001b[1;32m    314\u001b[0m istep \u001b[38;5;241m=\u001b[39m _index(step)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "group = 0\n",
    "\n",
    "directory = 'pseudo_testing_data_with_truth'\n",
    "directory_truth = 'degradation_data'\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [f for f in os.listdir(directory_truth) if f.endswith('.csv')]\n",
    "\n",
    "# Iterate over the shuffled file list and rename the files\n",
    "for i, file_name in enumerate(csv_files):\n",
    "    df = pd.read_csv(directory_truth + '/' + file_name)\n",
    "    ttf = df.iloc[0]['rul (months)']\n",
    "\n",
    "    ttf = int(ttf) #Added\n",
    "\n",
    "    if ttf >= 6:\n",
    "        random_integer = random.randint(1, ttf-1)\n",
    "\n",
    "        df = df[df['rul (months)'] >= random_integer]\n",
    "        df.to_csv(directory + '/' + file_name, index=False)\n",
    "    else:\n",
    "        df = df[df['rul (months)'] > 0]\n",
    "        df.to_csv(directory + '/' + file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory = 'pseudo_testing_data_with_truth'\n",
    "directory_student = 'pseudo_testing_data'\n",
    "\n",
    "if not os.path.exists(directory_student):\n",
    "    os.makedirs(directory_student)\n",
    "\n",
    "# Iterate over the shuffled file list and rename the files\n",
    "solution = pd.DataFrame()\n",
    "for i in range(50):\n",
    "    file_name = 'item_' + str(i) + '.csv'\n",
    "    df = pd.read_csv(directory + '/' + file_name)\n",
    "    \n",
    "    true_rul = df.iloc[-1]['rul (months)']\n",
    "    solution = pd.concat([solution, pd.DataFrame([{'item_index': 'item_{}'.format(i), \n",
    "                                     'label': 1 if true_rul<=6 else 0,\n",
    "                                     'true_rul': true_rul}])])\n",
    "    \n",
    "    df = df.drop(columns=['rul (months)'])\n",
    "    df.to_csv(directory_student + '/' + file_name, index=False)\n",
    "\n",
    "solution.to_csv(directory + '/' + 'Solution.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this script, you will find two folders in the directory:\n",
    "- `pseudo_testing_data_with_truth`: contains the generated pseudo testing data with the true RUL. Especially, in this folder, you will find a file `Solution.csv`, which contains the ground truth. You can directly use this file to evaluate your model.\n",
    "- `pseudo_testing_data`: contains the testing data without the true RUL.\n",
    "\n",
    "Below, you will find a script that allows you evaluate your prediction on the pseudo testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    # If you want an error message to be shown to participants, you must raise the error as a ParticipantVisibleError\n",
    "    # All other errors will only be shown to the competition host. This helps prevent unintentional leakage of solution data.\n",
    "    pass\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    '''\n",
    "    This metric is customized to measure the performance of remaining useful life prediction. \n",
    "    The participant is asked to predict whether the RUL of an item is less than 6 months: 1 - if RUL<=6 and 0 otherwise.\n",
    "    In the ground truth file \"Solution.csv\", there will be a column \"true_rul\" as well as a column \"label\".\n",
    "    If the predicted label matches the ground truth, a reward of 5 will be given.\n",
    "    If it does not match, then,\n",
    "    - A penalty of -10 will be given, if truth is 1 and prediction is 0;\n",
    "    - A penalty of -1/6*true_rul will be given, if truth is 0 and prediction is 1.\n",
    "\n",
    "    TODO: Add unit tests. We recommend using doctests so your tests double as usage demonstrations for competition hosts.\n",
    "    https://docs.python.org/3/library/doctest.html\n",
    "    # This example doctest works for mean absolute error:\n",
    "    >>> import pandas as pd\n",
    "    >>> row_id_column_name = \"item_index\"\n",
    "    >>> solution_data = {'item_index': [0, 1, 2, 3], 'label': [1, 0, 1, 0], 'true_rul': [5, 20, 1, 6]}\n",
    "    >>> submission_data = {'item_index': [0, 1, 2, 3], 'label': [1, 0, 0, 0]}\n",
    "    >>> solution = pd.DataFrame(solution_data)\n",
    "    >>> submission = pd.DataFrame(submission_data)\n",
    "    >>> score(solution.copy(), submission.copy(), row_id_column_name)\n",
    "    2\n",
    "    '''\n",
    "\n",
    "    # Initialize rewards and penalties\n",
    "    reward = 2\n",
    "    penalty_false_positive = -1/60\n",
    "    penalty_false_negative = -4\n",
    "\n",
    "    # Compare labels and calculate rewards/penalties\n",
    "    rewards_penalties = []\n",
    "    for _, (sol_label, sub_label, true_rul) in enumerate(zip(solution['label'], submission['label'], solution['true_rul'])):\n",
    "        if sol_label == sub_label:\n",
    "            rewards_penalties.append(reward)\n",
    "        elif sol_label == 1 and sub_label == 0:\n",
    "            rewards_penalties.append(penalty_false_negative)\n",
    "        elif sol_label == 0 and sub_label == 1:\n",
    "            rewards_penalties.append(penalty_false_positive * true_rul)\n",
    "        else:\n",
    "            rewards_penalties.append(0)  # No reward or penalty if labels don't match   \n",
    "    \n",
    "    return sum(rewards_penalties)\n",
    "\n",
    "\n",
    "row_id_column_name = \"item_index\"\n",
    "solution = pd.read_csv('pseudo_testing_data_with_truth/Solution.csv')\n",
    "\n",
    "# Put the path to your prediction result here:\n",
    "submission = \n",
    "\n",
    "print(score(solution.copy(), submission.copy(), row_id_column_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
